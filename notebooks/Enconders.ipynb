{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enconders.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8tRHOieFcUp",
        "colab_type": "text"
      },
      "source": [
        "https://blog.keras.io/building-autoencoders-in-keras.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giB3hVuySgta",
        "colab_type": "text"
      },
      "source": [
        "**Intento 1: autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iUlzE3-Fb5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "88e2c91d-27b0-4729-8c16-d403bdfdecb0"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rk9AzmnFdg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Qjp5JNFdjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naMfjugzFdmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpoEAJyPFdpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "cdeb797d-9366-4110-a16e-e6a7d98389ff"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBJKWIwFdsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "175d0968-5784-4fa7-902e-adc86231c935"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFLxsR5ZFb8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d39636ea-9688-4b51-9bc0-735b68ffd343"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.3647 - val_loss: 0.2712\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.2639 - val_loss: 0.2531\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.2431 - val_loss: 0.2312\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.2238 - val_loss: 0.2140\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2085 - val_loss: 0.2005\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1970 - val_loss: 0.1909\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1884 - val_loss: 0.1833\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1813 - val_loss: 0.1769\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1752 - val_loss: 0.1710\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1698 - val_loss: 0.1661\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1651 - val_loss: 0.1617\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1609 - val_loss: 0.1576\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1570 - val_loss: 0.1538\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1535 - val_loss: 0.1505\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1502 - val_loss: 0.1472\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1471 - val_loss: 0.1443\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1442 - val_loss: 0.1414\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1416 - val_loss: 0.1388\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1390 - val_loss: 0.1363\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1367 - val_loss: 0.1339\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1344 - val_loss: 0.1318\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1322 - val_loss: 0.1296\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1302 - val_loss: 0.1277\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1283 - val_loss: 0.1258\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1264 - val_loss: 0.1239\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1247 - val_loss: 0.1222\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1230 - val_loss: 0.1206\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1215 - val_loss: 0.1191\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1200 - val_loss: 0.1177\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1186 - val_loss: 0.1163\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1173 - val_loss: 0.1151\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1161 - val_loss: 0.1139\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1150 - val_loss: 0.1128\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1139 - val_loss: 0.1118\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1129 - val_loss: 0.1108\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1120 - val_loss: 0.1099\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1111 - val_loss: 0.1091\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1103 - val_loss: 0.1083\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1096 - val_loss: 0.1076\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1089 - val_loss: 0.1069\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1083 - val_loss: 0.1063\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1077 - val_loss: 0.1057\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1071 - val_loss: 0.1052\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1066 - val_loss: 0.1047\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1061 - val_loss: 0.1042\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1056 - val_loss: 0.1037\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1052 - val_loss: 0.1033\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1048 - val_loss: 0.1029\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1044 - val_loss: 0.1026\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1040 - val_loss: 0.1022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa510d2c550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBgIt68QFb-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc1QpbELGFdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "abd28c26-3101-4459-a5b6-94a14022e553"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtj7RK8YGFfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjdflk-yGhwd",
        "colab_type": "text"
      },
      "source": [
        "**Intento 2: Convolutional autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRfoapF5GFhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBnQ17lkGFjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjW4M0MtGFmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "baa64817-39aa-4a7b-fab2-a78e579bb5ba"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.2107 - val_loss: 0.1646\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1511 - val_loss: 0.1426\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1378 - val_loss: 0.1312\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1311 - val_loss: 0.1305\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1268 - val_loss: 0.1250\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1233 - val_loss: 0.1182\n",
            "Epoch 7/50\n",
            "47360/60000 [======================>.......] - ETA: 16s - loss: 0.1211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-dcb374fd4a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 validation_data=(x_test, x_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eypmoYZQGFom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwBZ3NgAGFrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WRVKmrRIMPw",
        "colab_type": "text"
      },
      "source": [
        "**Intento 3: Variational autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJtjmkBPJhXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_hPTL3_GFti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=128\n",
        "original_dim=28\n",
        "intermediate_dim=256\n",
        "latent_dim=512\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "h = Dense(intermediate_dim, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_sigma = Dense(latent_dim)(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkptG6fFGFwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "5b73a903-c16b-4727-f961-19b359836acc"
      },
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                              mean=0., std=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-0933f3d427e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# note that \"output_shape\" isn't necessary with the TensorFlow backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_sigma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Lambda' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Top7qC7nIm4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_h = Dense(intermediate_dim, activation='relu')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mFuRGqsIm7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# end-to-end autoencoder\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# encoder, from inputs to latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# generator, from latent space to reconstructed inputs\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(decoder_input)\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "generator = Model(decoder_input, _x_decoded_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w_X0dQyIm9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnhS3HBRInAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lHjJhhCInCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}